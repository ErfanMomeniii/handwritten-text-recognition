{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Handwritten Text Recognition from scratch"
      ],
      "metadata": {
        "id": "THJqNoof_0PQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "id": "D4oVq9wkAGRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e785c1-c4cf-4472-d95e-6896daca0f5a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.10/dist-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.16)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "od.download(\n",
        "    \"https://www.kaggle.com/datasets/nibinv23/iam-handwriting-word-database\"\n",
        ")"
      ],
      "metadata": {
        "id": "TC6ut3LJAW5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12d69982-a843-4af9-9c24-d6005ddc4bf1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping, found downloaded files in \"./iam-handwriting-word-database\" (use force=True to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/iam-handwriting-word-database/words_new.txt') as f:\n",
        "    contents = f.readlines()\n",
        "\n",
        "lines = [line.strip().split(sep=' ') for line in contents][18:]\n"
      ],
      "metadata": {
        "id": "xZ8Qzr-GEC6V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels=[i[8] for i in lines]\n",
        "addresses=[[i[0].split(sep='-')[0],i[0].split(sep='-')[1],i[0]] for i in lines]\n",
        "train_images=[cv2.imread(\"/content/iam-handwriting-word-database/iam_words/words/{}/{}/{}.png\".format(i[0],i[0]+\"-\"+i[1],i[2]),0) for i in addresses]\n",
        "train_images=[np.array(image).astype(np.float64)/255.0 for image in train_images]"
      ],
      "metadata": {
        "id": "nCX4sIxmOVWc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Conv2D, MaxPooling2D\n"
      ],
      "metadata": {
        "id": "oFTmRPPJDQIo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    model = Sequential([\n",
        "        Input(shape=(None,None,3)),\n",
        "        Conv2D(64, kernel_size=(3, 3), use_bias=False, activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=3),\n",
        "        Dense(len(labels), activation='softmax'),\n",
        "    ])\n",
        "    model.compile(SGD(learning_rate=.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(\n",
        "        [np.array(val) for val in train_images],\n",
        "        np.array([i for i in range(len(labels))]),\n",
        "        batch_size=1,\n",
        "        epochs=2\n",
        "    )\n"
      ],
      "metadata": {
        "id": "I5Vze2nNDTC7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}